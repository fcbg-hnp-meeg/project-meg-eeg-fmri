{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3caea1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "# Crop it (for images from thispersondoesnotexist)\n",
    "def cropit(image):\n",
    "    # Crop the image from thispersondoesnotexist here to remove watermarking\n",
    "    # Originally 1024 x 1024\n",
    "    orgsize = 1024\n",
    "    y=55  # that is enough\n",
    "    height=orgsize-2*y\n",
    "    x=y\n",
    "    width=orgsize-2*y    \n",
    "    image = image[y:y+height, x:x+width]\n",
    "    \n",
    "    return image\n",
    "    \n",
    "# Gray scale it\n",
    "def grayscaleit(image):\n",
    "    # Convert image to grayscale\n",
    "    image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Normalize luminance and contrast of grayscale image\n",
    "def normit(image):\n",
    "    # Calculate the histogram\n",
    "    histogram, bins = np.histogram(image.flatten(), bins=256, range=[0, 256])\n",
    "\n",
    "    # Calculate the cumulative distribution function (CDF)\n",
    "    cdf = histogram.cumsum()\n",
    "    cdf_normalized = cdf * histogram.max() / cdf.max()\n",
    "\n",
    "    # Perform histogram equalization\n",
    "    equalized_image = np.interp(image.flatten(), bins[:-1], cdf_normalized).reshape(image.shape)\n",
    "\n",
    "    # Normalize the image to the range [0, 255]\n",
    "    normalized_image = ((equalized_image - equalized_image.min()) / (equalized_image.max() - equalized_image.min())) * 255\n",
    "\n",
    "    # Convert the image to 8-bit unsigned integer\n",
    "    normalized_image = normalized_image.astype(np.uint8)\n",
    "\n",
    "    return normalized_image\n",
    "\n",
    "def adjustnormit(image, target_luminance, target_contrast):\n",
    "    # Calculate the average luminance and average contrast\n",
    "    average_luminance = np.mean(image)\n",
    "    average_contrast = np.std(image)\n",
    "\n",
    "    # Calculate the difference in average values\n",
    "    delta_luminance = target_luminance - average_luminance\n",
    "    delta_contrast = target_contrast - average_contrast\n",
    "\n",
    "    # Adjust the image pixel values based on the differences\n",
    "    normalized_image = (image + delta_luminance) * (target_contrast / average_contrast)\n",
    "\n",
    "    # Clip the pixel values to ensure they are within the valid range [0, 255]\n",
    "    normalized_image = np.clip(normalized_image, 0, 255)\n",
    "\n",
    "    # Convert the image to 8-bit unsigned integer\n",
    "    normalized_image = normalized_image.astype(np.uint8)\n",
    "    \n",
    "    return normalized_image\n",
    "\n",
    "# Randomise image phases \n",
    "def scramblinspacefreq(image):\n",
    "    # Convert the image to the frequency domain\n",
    "    fft_pic = np.fft.fftn(pic, axes=(0, 1))\n",
    "\n",
    "    # Randomize the phases in the frequency spectrum\n",
    "    random_phases = np.exp(1j * 2 * np.pi * np.random.rand(*fft_pic.shape))\n",
    "\n",
    "    # Apply the randomized phases to the original spectrum\n",
    "    scrambled_fft_pic = np.abs(fft_pic) * random_phases\n",
    "\n",
    "    # Transform the image back to the spatial domain\n",
    "    scrambled_pic = np.fft.ifftn(scrambled_fft_pic, axes=(0, 1)).real\n",
    "\n",
    "    # Normalize the scrambled image to the original image's range\n",
    "    scrambled_pic = (scrambled_pic - scrambled_pic.min()) / (scrambled_pic.max() - scrambled_pic.min())\n",
    "    \n",
    "    return scrambled_pic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9837c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "136c07cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vrochas\\AppData\\Local\\Temp\\ipykernel_12292\\3824691120.py:19: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pic = imageio.imread(folder_path+ \"\\\\\" +image_file)\n"
     ]
    }
   ],
   "source": [
    "## This loop will read images in folder\n",
    "## Crop 55 pixels on every borders\n",
    "## Transform to grayscale\n",
    "## and Save a new folder\n",
    "\n",
    "# Folder path containing the images\n",
    "folder_path = r'D:\\project_meg-eeg-fMRI\\tasks\\faces\\stim\\thispersondoesnotexist'\n",
    "    \n",
    "# List all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Filter only image files (modify the extensions as required)\n",
    "image_files = [f for f in file_list if f.endswith(('.png', '.jpg', '.gif'))]\n",
    "\n",
    "# Loop through each image file and apply the transformation\n",
    "for image_file in image_files:\n",
    "\n",
    "    # Load the image\n",
    "    pic = imageio.imread(folder_path+ \"\\\\\" +image_file)\n",
    "\n",
    "    # Crop the image from thispersondoesnotexist here to remove watermarking\n",
    "    pic = cropit(pic)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    pic = grayscaleit(pic)\n",
    "    \n",
    "#    # Normalize luminance and contrast\n",
    "#    pic = normit(pic)\n",
    "    \n",
    "    # Normalize to adjusted luminance and contrast \n",
    "    target_luminance = 130\n",
    "    target_contrast = 50\n",
    "    pic = adjustnormit(pic, target_luminance, target_contrast)\n",
    "    \n",
    "    # Save the gray image\n",
    "    imageio.imwrite(folder_path+\"\\\\gray\\\\\"+\"g_\"+image_file, np.uint8(pic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90ea037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vrochas\\AppData\\Local\\Temp\\ipykernel_12292\\728909054.py:19: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pic = imageio.imread(folder_path+ \"\\\\\" +image_file)\n"
     ]
    }
   ],
   "source": [
    "## This loop will read images in folder\n",
    "## randomsied the phases of the image decomposition\n",
    "## and Save the results\n",
    "\n",
    "# Folder path containing the images\n",
    "#folder_path = r'D:\\project_meg-eeg-fMRI\\tasks\\faces\\stim\\Stirling\\frontal_neutral'\n",
    "folder_path = r'D:\\project_meg-eeg-fMRI\\tasks\\faces\\stim\\thispersondoesnotexist\\gray'\n",
    "    \n",
    "# List all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Filter only image files (modify the extensions as required)\n",
    "image_files = [f for f in file_list if f.endswith(('.png', '.jpg', '.gif'))]\n",
    "\n",
    "# Loop through each image file and apply the transformation\n",
    "for image_file in image_files:\n",
    "\n",
    "    # Load the image\n",
    "    pic = imageio.imread(folder_path+ \"\\\\\" +image_file)\n",
    "\n",
    "    # Randomize phases \n",
    "    scrambled_pic = scramblinspacefreq(pic)\n",
    "    \n",
    "    # Save the scrambled image\n",
    "    imageio.imwrite(folder_path+\"\\\\\"+\"scr_\"+image_file, np.uint8(scrambled_pic * 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fbff559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g_fa2_01.jpg',\n",
       " 'g_fa2_02.jpg',\n",
       " 'g_fa2_03.jpg',\n",
       " 'g_fa2_04.jpg',\n",
       " 'g_fa2_05.jpg',\n",
       " 'g_fa2_06.jpg',\n",
       " 'g_fa2_07.jpg',\n",
       " 'g_fa3_01.jpg',\n",
       " 'g_fa3_02.jpg',\n",
       " 'g_fa3_03.jpg',\n",
       " 'g_fa3_04.jpg',\n",
       " 'g_fa3_05.jpg',\n",
       " 'g_fa3_06.jpg',\n",
       " 'g_fa3_07.jpg',\n",
       " 'g_fa4_01.jpg',\n",
       " 'g_fa4_02.jpg',\n",
       " 'g_fa4_03.jpg',\n",
       " 'g_fa4_04.jpg',\n",
       " 'g_fa4_05.jpg',\n",
       " 'g_fa4_06.jpg',\n",
       " 'g_fa4_07.jpg',\n",
       " 'g_ma2_01.jpg',\n",
       " 'g_ma2_02.jpg',\n",
       " 'g_ma2_03.jpg',\n",
       " 'g_ma2_04.jpg',\n",
       " 'g_ma2_05.jpg',\n",
       " 'g_ma2_06.jpg',\n",
       " 'g_ma2_07.jpg',\n",
       " 'g_ma3_01.jpg',\n",
       " 'g_ma3_02.jpg',\n",
       " 'g_ma3_03.jpg',\n",
       " 'g_ma3_04.jpg',\n",
       " 'g_ma3_05.jpg',\n",
       " 'g_ma3_06.jpg',\n",
       " 'g_ma3_07.jpg',\n",
       " 'g_ma4_01.jpg',\n",
       " 'g_ma4_02.jpg',\n",
       " 'g_ma4_03.jpg',\n",
       " 'g_ma4_04.jpg',\n",
       " 'g_ma4_05.jpg',\n",
       " 'g_ma4_06.jpg',\n",
       " 'g_ma4_07.jpg',\n",
       " 'scr_g_fa2_01.jpg',\n",
       " 'scr_g_fa2_02.jpg',\n",
       " 'scr_g_fa2_03.jpg',\n",
       " 'scr_g_fa2_04.jpg',\n",
       " 'scr_g_fa2_05.jpg',\n",
       " 'scr_g_fa2_06.jpg',\n",
       " 'scr_g_fa2_07.jpg',\n",
       " 'scr_g_fa3_01.jpg',\n",
       " 'scr_g_fa3_02.jpg',\n",
       " 'scr_g_fa3_03.jpg',\n",
       " 'scr_g_fa3_04.jpg',\n",
       " 'scr_g_fa3_05.jpg',\n",
       " 'scr_g_fa3_06.jpg',\n",
       " 'scr_g_fa3_07.jpg',\n",
       " 'scr_g_fa4_01.jpg',\n",
       " 'scr_g_fa4_02.jpg',\n",
       " 'scr_g_fa4_03.jpg',\n",
       " 'scr_g_fa4_04.jpg',\n",
       " 'scr_g_fa4_05.jpg',\n",
       " 'scr_g_fa4_06.jpg',\n",
       " 'scr_g_fa4_07.jpg',\n",
       " 'scr_g_ma2_01.jpg',\n",
       " 'scr_g_ma2_02.jpg',\n",
       " 'scr_g_ma2_03.jpg',\n",
       " 'scr_g_ma2_04.jpg',\n",
       " 'scr_g_ma2_05.jpg',\n",
       " 'scr_g_ma2_06.jpg',\n",
       " 'scr_g_ma2_07.jpg',\n",
       " 'scr_g_ma3_01.jpg',\n",
       " 'scr_g_ma3_02.jpg',\n",
       " 'scr_g_ma3_03.jpg',\n",
       " 'scr_g_ma3_04.jpg',\n",
       " 'scr_g_ma3_05.jpg',\n",
       " 'scr_g_ma3_06.jpg',\n",
       " 'scr_g_ma3_07.jpg',\n",
       " 'scr_g_ma4_01.jpg',\n",
       " 'scr_g_ma4_02.jpg',\n",
       " 'scr_g_ma4_03.jpg',\n",
       " 'scr_g_ma4_04.jpg',\n",
       " 'scr_g_ma4_05.jpg',\n",
       " 'scr_g_ma4_06.jpg',\n",
       " 'scr_g_ma4_07.jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the list of image files in:\n",
    "folder_path = r'D:\\project_meg-eeg-fMRI\\tasks\\faces\\stim\\thispersondoesnotexist\\gray'\n",
    "    \n",
    "# List all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Filter only image files (modify the extensions as required)\n",
    "image_files = [f for f in file_list if f.endswith(('.png', '.jpg', '.gif'))]\n",
    "image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36e15a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here is an extra function in order to rescale an image from another set (the control images)\n",
    "\n",
    "import imageio\n",
    "import scipy.ndimage\n",
    "\n",
    "def rescale_image(image, new_size):\n",
    "    \n",
    "    # Rescale the image using scipy.ndimage.zoom\n",
    "    scaled_image = scipy.ndimage.zoom(image, (new_size[0] / image.shape[0], new_size[1] / image.shape[1]))\n",
    "\n",
    "    return scaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa6f997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vrochas\\AppData\\Local\\Temp\\ipykernel_7836\\242208244.py:19: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pic = imageio.imread(folder_path+ \"\\\\\" +image_file)\n"
     ]
    }
   ],
   "source": [
    "## This loop will read images in folder\n",
    "## Transform to grayscale\n",
    "## Rescale to desired size\n",
    "## and Save a new folder\n",
    "\n",
    "# Folder path containing the images\n",
    "folder_path = r'D:\\project_meg-eeg-fMRI\\tasks\\faces\\stim\\control_images(stablediff)'\n",
    "    \n",
    "# List all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Filter only image files (modify the extensions as required)\n",
    "image_files = [f for f in file_list if f.endswith(('.png', '.jpg', '.gif'))]\n",
    "\n",
    "# Loop through each image file and apply the transformation\n",
    "for image_file in image_files:\n",
    "\n",
    "    # Load the image\n",
    "    pic = imageio.imread(folder_path+ \"\\\\\" +image_file)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    pic = grayscaleit(pic)\n",
    "    \n",
    "    # Rescale\n",
    "    new_size = (914, 914)\n",
    "    pic = rescale_image(pic, new_size)\n",
    "    \n",
    "    # Normalize to adjusted luminance and contrast \n",
    "    target_luminance = 130\n",
    "    target_contrast = 50\n",
    "    pic = adjustnormit(pic, target_luminance, target_contrast)\n",
    "    \n",
    "    # Save the gray image\n",
    "    imageio.imwrite(folder_path+\"\\\\rescale\\\\\"+\"s_\"+image_file, np.uint8(pic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b656d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
